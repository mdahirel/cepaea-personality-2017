---
title: "Personality and shell morph in *Cepaea nemoralis* snails"
author: 
  - "**Maxime Dahirel** (script author)"
  - Valentin Gaudu
  - Armelle Ansart
date: "12/06/2020"
output: 
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

```{r load-packages}
######all packages + R up to date as of 13 June 2020

library(matrixStats)

library(tidyverse)

library(rstan)
library(tidybayes)
library(bayesplot)
library(brms)
rstan_options(auto_write = TRUE)
options(mc.cores = 2)

library(QGglmm)

library(cowplot)
library(patchwork)

library(here)
```

# Introduction

(see [manuscript](https://doi.org/10.1101/866947) for details)

## Aims of study

We want to see if there are links between behaviour and shell morph in the snail *Cepaea nemoralis*. This species, common in western Europe and introduced in North America, has been the subject of many evolutionary studies in the last decades, mainly related to its shell polymorphism and its relation with abiotic (climate) and biotic (predators) selection pressures. We here focus on one aspect of shell polymorphism, number of bands, for simplicity.

## General methods

In 2017, snails of 3 morphs were caught in two habitats that differ by their level of shading. They were then brought to the lab where we measured a proxy of boldness (simulating predator attacks by pinching snails) and exploration/activity, the latter under a range of 4 temperatures. A total of 360 snails were tested.

We came back the following year to re-sample snails, this time at random with respect to banding. This allowed us to see whether the two habitats differed in their proportion of (darker) highly banded snails.

# Analysis

## Loading datasets

```{r load-datafiles}
## Load main dataset

data0 <- read_csv(here("data","cepaea-2017-dataset.csv"))

data_shells0 <- read_csv(here("data","cepaea-2018-shells.csv"))

```


The `data0` dataset contains the following variables, collected on 360 snails sampled and tested in 2017:

- `id`: unique individual ID for each snail

- `landscape`: name of the landscape of origin. "Garenne" (French for "warren") is the open, sun-exposed garden landscape, "Marais" ("swamp") the shaded, humid, woodlot

- `box` : unique ID for the box in which snails are stored in the lab

- `band_phenotype`: 0, 3, or 5 dark bands on the shell

- `boldness`: time (sec) to resume activity after a simulated predator attack (pinching on the foot)

- `order.b`: trial order for boldness (there were two boldness trials)

- `fpt`: time (sec) to leave the test area in the exploration trial, taken as our measure of exploration/activity

- `temperature`: the temperature of the "exploration" trial

- `order.temp`: trial order for exploration. There were 4 exploration trials, one per temperature. Half the snails were tested in increasing order of temperature, the other half in decreasing order

Note that the data are not organized fully following 'tidy' principles: there are no "intrinsic" links between the `fpt` and `boldness` observations that are on the same row (besides being from the same individuals). All boldness tests were done first, then all the exploration tests. Data are stored this way to minimize the number of NAs.

The `data_shells0` dataset (used in Supplementary Material only) has the following variables, collected the following year:

- `landscape`: see previous

- `N_0bands`, `N_midband`, `N_2bands`, `N_3bands`, `N_5bands`: number of snails caught per band phenotype (in *Cepaea*, band phenotypes are traditionally coded with numbers from 1-5, going from top to bottom, with a 0 given if the band is absent. Our five categories correspond to phenotypes 00000, 00300, 00045, 00345 and 12345 respectively)

## Data preprocessing

We first need to add a censoring variable, to correctly analyze snails that did not respond before the end of observations (20 minutes):

```{r data-wrangling-censoring}

data<-data0 %>% 
  mutate(censored_fpt = as.numeric(fpt>=1200),
         censored_bold = as.numeric(boldness >= 1200)
  )
```

We then scale and recode several variables to make the model easier to fit and coefficients easier to interpret:
```{r data-wrangling-recoding}

data<-data %>% 
  mutate(s_temp = scale(temperature)[,1], #centred and scaled
         c_order.temp = order.temp - 2.5, ## centred without scaling
         c_order.b = order.b - 1.5, ## same
         c_landscape = -0.5 + as.numeric(landscape == "Marais"), ## same
         ##recoding
         is0b=(band_phenotype=="0b")-mean(band_phenotype=="0b"),
         is3b=(band_phenotype=="3b")-mean(band_phenotype=="3b"),
         is5b=(band_phenotype=="5b")-mean(band_phenotype=="5b")
)

mean_temp <- attr(scale(data$temperature), "scaled:center") ##useful for plotting
sd_temp <- attr(scale(data$temperature), "scaled:scale")
```


If you looked at the data, you may have noticed there are only 2 boldness observations per individual, but 4 "exploration" observations. This means there are many NAs in the table. The `brms` package can easily analyse multivariate data where the response vectors do not have the same length using the `subset()` argument to specify which values to use for each submodel. However ([due to constraints in coding as of June 2020, may change in the future](https://github.com/paul-buerkner/brms/issues/895)), there still needs to be values for all responses on all rows (or else rows with NAs will be discarded). So we need to fill the NAs in the boldness column with dummy values (don't worry, they will be ignored in fitting). We do actually do that by creating new columns rather than overwriting, to prevent any accidental mistakes:

```{r data-wrangling-subset}
data <- data %>% 
  mutate(is.valid.bold = as.numeric(is.na(boldness) == FALSE), ### if it's not a NA in the original column, then it's valid,
         censored_bold2 = c(censored_bold[1:720], rep(1,720)),
         boldness2 = c(boldness[1:720], rep(1200, 720)) 
         ### and we fill the cells that won't be used with dummy values
  )
```


## Main model

Now, let's fit our main model (please see description in the methods and supplementary material of the paper).

```{r multivariate-model-formulas}
bf_explo <- bf(fpt |cens(censored_fpt) ~ ((is3b+is5b) * c_landscape) * s_temp + c_order.temp +
                    (s_temp | p | box) + (s_temp | q | id), family = lognormal)

bf_boldness <- bf(boldness2 | subset(is.valid.bold) + cens(censored_bold2) ~ (is3b+is5b) * c_landscape + c_order.b +
                    (1 | p | box) + (1 | q | id), family = lognormal)
```

One may wonder (we did, and a reviewer did too) whether among-individual variation could differ among morphs. We believed a priori, based on Dingemanse and Dochtermann 2013 (https://doi.org/10.1111/1365-2656.12013) that we simply do not have enough data per morph to test this. But it's still worthwhile to have a look, as an illustration (will not be presented in the manuscript):

```{r multivariate-model-formulas-alt}
bf_explo2 <- bf(fpt |cens(censored_fpt) ~ ((is3b+is5b) * c_landscape) * s_temp + c_order.temp +
                    (s_temp | p | box) + (s_temp | q | gr(id,by = band_phenotype)), family = lognormal)

bf_boldness2 <- bf(boldness2 | subset(is.valid.bold) + cens(censored_bold2) ~ (is3b+is5b) * c_landscape + c_order.b +
                    (1 | p | box) + (1 | q | gr(id,by = band_phenotype)), family = lognormal)
```

```{r multivariate-model-priors}
### PRIOR
prior_multi <- c(
  set_prior("normal(0, 1)", class = "b",resp=c("boldness2","fpt")), ##### Fixed effects; weakly informative prior for response centred and scaled
  set_prior("normal(log(400),0.5)",class=c("Intercept"),resp=c("boldness2","fpt")),
  set_prior("lkj(3)", class = "cor"),
  set_prior("normal(0,1)",class = "sd",resp=c("boldness2","fpt")), #halfnormal implied for "sd" and "sigma" class parameters
  set_prior("normal(0,1)",class = "sigma",resp=c("boldness2","fpt"))
)

```


```{r multivariate-model}
### fit models ##NB: the sampler may throw some initialization errors at the beginning because it falls on an impossible starting value
### but then come out fine

if(file.exists(here("R_output","model_main.Rdata"))){
  # this if-else statement is avoid re-fitting a model if there is already one existing in R_output
  # to override, re-run and re-save manually the model by selecting only relevant code lines, instead of running the entire chunk
  load(here("R_output","model_main.Rdata"))
  load(here("R_output","model_alt.Rdata"))
  }else
    {
mod <- brm(mvbf(bf_explo + bf_boldness, rescor = FALSE),
              data = data, 
              chains=4, iter = 12000, warmup = 2000, 
## put lower N_chains, N_iter, N_warmup if you just want to have a quick look; convergence happens pretty fast
## the increased # of iterations compared to default is mostly there to let individuals correlations reach a good enough effective sample size
              prior = prior_multi, seed = 42,
              control=list(adapt_delta = 0.95,max_treedepth=15)
)

mod2 <- brm(mvbf(bf_explo2 + bf_boldness2, rescor = FALSE),
              data = data, 
              chains=4, iter = 12000, warmup = 2000, 
              prior = prior_multi, seed = 42,
              control=list(adapt_delta = 0.95,max_treedepth=15)
)### probably should need some more iterations, but good enough for a quick comparison

save(list="mod", file=here("R_output","model_main.Rdata"))
save(list="mod2", file=here("R_output","model_alt.Rdata"))
}
```
The models take between 20 minutes and 1h each to run on an ASUS X556UQ laptop with 12Go memory, depending on the number of chains allowed to run in parallel (see `options(mc.cores = ???)` at the top of this file) and whatever else is running at the same time.

One can use diagnostics in the `loo` package and their implementation in `brms` to compare the `mod` and `mod2`. Given the conclusions are either that the models are not distinguishable (boldness), or that the simplest is better (fpt), we choose to carry on with the simplest one only as we originally planned:

```{r loo-compare}
loo1=loo(mod,resp="boldness2") 
## note that it may throw warnings, in that case, consider kfold(), but the conclusions should be similar
loo2=loo(mod2,resp="boldness2")
loo_compare(loo1,loo2)

loo1=loo(mod,resp="fpt")
loo2=loo(mod2,resp="fpt")
loo_compare(loo1,loo2)
```

# Postprocessing : plots and summaries

## Summaries and posterior checks

We check summaries to be sure convergence has been reached ($\widehat{R} \simeq 1$), effective sample sizes are correct, and to get posterior means and intervals. The default `summary()` call gives quantile intervals, so we work a bit to get higher density intervals. We also use rank plots (http://arxiv.org/abs/1903.08008) to visually check convergence and stationarity:

```{r summaries}
summary(mod)  # look at effective sample sizes

summary_mod <- mod %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_", "cor_", "sigma"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>% 
  print(n=Inf)

mcmc_rank_overlay(mod, pars = summary_mod$name)
```

We can "uncenter" the fixed effects predictor to get back morph specific intercepts and temperature slopes:

```{r morph-specific_fixef}
p_scaling<-data %>% 
  select(band_phenotype,is0b,is3b,is5b) %>% 
  distinct()

is3b_if0<-(filter(p_scaling,band_phenotype=="0b")$is3b)
is3b_if3<-(filter(p_scaling,band_phenotype=="3b")$is3b)
is3b_if5<-(filter(p_scaling,band_phenotype=="5b")$is3b)

is5b_if0<-(filter(p_scaling,band_phenotype=="0b")$is5b)
is5b_if3<-(filter(p_scaling,band_phenotype=="3b")$is5b)
is5b_if5<-(filter(p_scaling,band_phenotype=="5b")$is5b)

fixef(mod,summary=FALSE) %>% 
  as.data.frame() %>% 
  mutate(bold_intercept_0b = boldness2_Intercept + (is3b_if0)*boldness2_is3b + (is5b_if0)*boldness2_is5b,
         bold_intercept_3b = boldness2_Intercept + (is3b_if3)*boldness2_is3b + (is5b_if3)*boldness2_is5b,
         bold_intercept_5b = boldness2_Intercept + (is3b_if5)*boldness2_is3b + (is5b_if5)*boldness2_is5b,
         fpt_intercept_0b = fpt_Intercept + (is3b_if0)*fpt_is3b + (is5b_if0)*fpt_is5b,
         fpt_intercept_3b = fpt_Intercept + (is3b_if3)*fpt_is3b + (is5b_if3)*fpt_is5b,
         fpt_intercept_5b = fpt_Intercept + (is3b_if5)*fpt_is3b + (is5b_if5)*fpt_is5b,
         fpt_slope_0b = fpt_s_temp + (is3b_if0)*`fpt_is3b:s_temp` + (is5b_if0)*`fpt_is5b:s_temp`,
         fpt_slope_3b = fpt_s_temp + (is3b_if3)*`fpt_is3b:s_temp` + (is5b_if3)*`fpt_is5b:s_temp`,
         fpt_slope_5b = fpt_s_temp + (is3b_if5)*`fpt_is3b:s_temp` + (is5b_if5)*`fpt_is5b:s_temp`) %>% 
  select(bold_intercept_0b:fpt_slope_5b) %>% 
  mutate(bold_diff_35 = bold_intercept_3b - bold_intercept_5b, #the 0 vs 3 and 0 vs 5 contrasts are already in the model summary
         fpt_diff_35 = fpt_intercept_3b - fpt_intercept_5b,
         fpt_diffslope_35 = fpt_slope_3b - fpt_slope_5b) %>% 
  mutate(.iteration = 1:dim(.)[1]) %>% 
  pivot_longer(-.iteration) %>% 
  group_by(name) %>% 
  mean_hdi()
```
(we also, at the same time, collect the 3 vs 5 contrasts in intercept and slopes, as they are not readily available from the summaries printed before)

We then do some posterior predictive checks:

```{r pp_checks}
###harder to find good pp_checks because of censoring, but ribbons (ranked observed values overlaid on prediction intervals) seems a-OK
###note the prediction behaviour for the censored datapoints
ppc_ribbon(yrep=predict(mod,newdata=data,resp="fpt",summary=FALSE),
           x=rank(predict(mod,resp="fpt")[,1]),
           y=data$fpt,
           prob = 0.5, prob_outer=0.95)

ppc_ribbon(yrep=predict(mod,newdata=data[1:720,],resp="boldness2",summary=FALSE),
           x=rank(predict(mod,resp="boldness2",newdata=data[1:720,])[,1]),
           y=data$boldness2[1:720],
           prob = 0.5, prob_outer=0.95)
```




## Making figures

(Fig. 1 is a set of photographs, so we start at Fig.2 for data plots)

### Figure 2

```{r figure2-1}
##### first get posterior predictions
## at average temperatures/trial order/landscape (everything else except phenotype is averaged out)

newdata <- data %>% 
  select(band_phenotype,is3b,is5b) %>% 
  distinct() %>% 
  mutate(s_temp = 0, 
         c_order.b = 0, c_order.temp = 0, 
         c_landscape = 0, 
         #id = data$id[1], #won't be used (re_formula = NA), but may be needed for prediction on older versions of brms (I think)
         #box = data$box[1],
         is.valid.bold=1) %>%
  add_fitted_draws(model = mod, re_formula = NA, scale="linear",resp=c("boldness2")) %>%
  ### the behaviour of scale="response" seems to give the mean on the response scale, but I'd like the median; more representative for a lognormal
  ### makes it easier to match to observed data points
  ### so I use scale = "linear" (gives the mean on the log scale, so the median on the response scale)
  ### and I back-transform after
  mutate(boldness = exp(.value)) %>% 
  select(-(.value)) ## to avoid merge conflicts with the second table

newdata2 <- data %>% 
  select(band_phenotype,is3b,is5b) %>% 
  distinct() %>% 
  mutate(s_temp = 0, 
         c_order.b = 0, c_order.temp = 0, 
         c_landscape = 0, 
         #id = data$id[1], 
         #box = data$box[1],
         is.valid.bold=1) %>%
  add_fitted_draws(model = mod, re_formula = NA, scale = "linear",resp=c("fpt")) %>%
  mutate(fpt = exp(.value)) %>% 
  select(-(.value))

newdata<-inner_join(newdata,newdata2) ; rm(newdata2)
```


```{r figure2-2}
### for boldness
fig_2a <- filter(data,is.na(boldness)==FALSE) %>% 
  ggplot() +
  geom_hline(yintercept=1200,lty=2)+
  geom_line(aes(x = as.numeric(factor(band_phenotype))+0.8*c_order.b, y=boldness, group=id),col = "grey", show.legend = FALSE,alpha=0.4) +
  geom_violin(data=newdata,aes(y = boldness, x = band_phenotype, fill = band_phenotype),draw_quantiles = 0.5, show.legend = FALSE,alpha=0.8) +
  scale_fill_brewer(palette = "YlOrBr", direction = 1) +
  scale_y_log10(name = "Boldness (latency, sec)", limits = c(3, 1200), breaks = c(5, 10, 20, 50, 100, 200, 500, 1000)) +
  scale_x_discrete(name = "", labels = c("0 bands", "3 bands", "5 bands")) +
  theme_half_open(11) +
  ggtitle("A")


###arrow_bold
arrow_bold=ggplot()+
  geom_segment(aes(x=c(0,0),xend=c(0,0),y=c(0.05,0.95),yend=c(0.95,0.05)),arrow=arrow())+
  geom_text(aes(x=c(0,0),y=c(0,1),label=c("bolder","shyer")))+theme_void()

###arrow_fpt
arrow_fpt=ggplot()+
  geom_segment(aes(x=c(0,0),xend=c(0,0),y=c(0.05,0.95),yend=c(0.95,0.05)),arrow=arrow())+
  geom_text(aes(x=c(0,0),y=c(0,1),label=c("faster","slower")))+theme_void()

### for exploration
fig_2b <- ggplot(data = data) + 
  geom_hline(yintercept=1200,lty=2)+
  geom_line(aes(x = as.numeric(factor(band_phenotype))+0.3*s_temp,fpt, group=id),col = "grey", show.legend = FALSE,alpha=0.4) +
  geom_violin(data=newdata, aes(y = fpt, x = band_phenotype, fill = band_phenotype),draw_quantiles = 0.5, show.legend = FALSE, alpha= 0.8) +
  scale_fill_brewer(palette = "YlOrBr", direction = 1) +
  scale_y_log10(name = "Exploration (first passage time, sec)", limits = c(250, 1200), breaks = c(250, 500, 750, 1000)) +
  scale_x_discrete(name = "Shell phenotype", labels = c("0 bands", "3 bands", "5 bands")) +
  #geom_line(data = tab, aes(x = band_genotype, y = fpt,group=id), position=position_dodge(width = 0.9),col = "grey", show.legend = FALSE,alpha=0.3)+
  theme_half_open(11) +
  ggtitle("B")
```


```{r figure2-3}
## over range of temperatures (everything else is averaged out)
fig_2c <- expand_grid(Temperature = c(15:25), 
              c_order.b = 0, 
              c_order.temp = 0, 
              c_landscape = 0, 
              #id = data$id[1], 
              #box = data$box[1],
              is3b = 0,
              is5b = 0,
              is.valid.bold=1) %>%
  mutate(s_temp = (Temperature-mean_temp)/sd_temp) %>%
  add_fitted_draws(model = mod, re_formula = NA,scale = "linear",resp="fpt") %>%
  mutate(fpt = exp(.value)) %>% 
ggplot()+
  geom_hline(yintercept=1200,lty=2)+
  geom_line(data = data, aes(x = temperature, y = fpt,group=id), col = "grey", show.legend = FALSE,alpha=0.3) + 
  stat_lineribbon(aes(x = Temperature,y = fpt), .width = 0.95,show.legend=FALSE,fill="pink", alpha= 0.8,point_interval=mean_hdi) +
  scale_y_log10(name = "", limits = c(250, 1200),breaks = c(250, 500, 750, 1000)) +
  scale_x_continuous(name = "Test temperature (°C)", limits = c(14, 26),breaks=15:25, labels=c(15,"","","","",20,"","","","",25)) +
  theme_half_open(11) +
  ggtitle("C")
```


```{r figure2}
arrow_bold + fig_2a + plot_spacer() + arrow_fpt + fig_2b + fig_2c + plot_layout(nrow = 2, widths= c(1,5,5))

##we annotate (A,B,C) using ggtitle in each plot rather than plot_annotation (which I'd prefer), because plot_annotation annotates ALL the plots, and here that means even the arrows

```

### Figure 3

Here we want to display the variation partitioning. 

The first step is extracting the relevant latent variances (fixed, random, "residual"). Relatively straightforward, but to get the correct total VB and VI for exploration, we need to account for individual/box variation in the response to temperature. We here apply Johnson 2014 MEE (doi 10.1111/2041-210X.12225) to get the total random variance of one trait at one observation level (see manuscript for names of each variance component):

(this might take some time; about 10 min on my laptop)
```{r latent-varcomps}

if(file.exists(here("R_output","latent_varcomps.Rdata")))
  {
  load(here("R_output","latent_varcomps.Rdata"))
  }else
    {


### need to create a design matrix for each level:
design_id <- as.matrix(expand_grid(Intercept=rep(1,length(unique(data$id))),s_temp=unique(data$s_temp)))
design_box <- as.matrix(expand.grid(Intercept=rep(1,length(unique(data$box))),s_temp=unique(data$s_temp)))

##now we're good to go, let's get the posterior for each latent variance component (and the fixed intercept, we'll need it later) back

varcomps_fpt_latent <- tibble(
  beta0 = posterior_samples(mod,pars="b_fpt_Intercept")[,1],
  VF= rowVars(posterior_linpred(mod, re_formula = NA,scale = "linear",resp="fpt")),
  VFstate= rowVars(posterior_linpred(mod, 
                                     newdata= data %>% mutate(s_temp=0,c_order.temp=0,c_order.b = 0), 
                                     re_formula = NA,scale = "linear",resp="fpt")),
  ##above: modified newdata because it is the variance of fixed effect assuming individuals only differ in state
  VI = VarCorr(mod,summary=FALSE)$id$cov[,c("fpt_Intercept","fpt_s_temp"),c("fpt_Intercept","fpt_s_temp")] %>% 
    array_tree(.,margin=1) %>% 
    ##apply equation (11) of Johnson 2014 MEE over the posterior
    map(.,~mean(diag(design_id %*% . %*% t(design_id)))) %>% 
    as_vector(),
  VIint= (VarCorr(mod,summary=F)$id$sd[,"fpt_Intercept"])^2,
  VB= VarCorr(mod,summary=FALSE)$box$cov[,c("fpt_Intercept","fpt_s_temp"),c("fpt_Intercept","fpt_s_temp")] %>%
    array_tree(.,margin=1) %>% 
    ##apply equation (11) of Johnson 2014 MEE over the posterior
    map(.,~mean(diag(design_box %*% . %*% t(design_box)))) %>% 
    as_vector(),
  VBint= (VarCorr(mod,summary=F)$box$sd[,"fpt_Intercept"])^2,
  VD=(posterior_samples(mod,pars="sigma_fpt")[,1])^2
  ) %>% 
  mutate(VP = select(.,c(VF,VI,VB,VD)) %>% rowSums() ) %>% 
  mutate(trait="Exploration",type="latent") %>% 
  mutate(.iteration = 1) %>% mutate(.iteration = cumsum(.iteration))


varcomps_bold_latent <- tibble(
  beta0=posterior_samples(mod,pars="b_boldness2_Intercept")[,1],
  VF=rowVars(posterior_linpred(mod, re_formula = NA,scale = "linear",resp="boldness2")),
  ##checked! works as intended and only provide predictions for the actual boldness values, it discards the dummies added for the multivariate model (see above _ chunk data-wrangling-subset)
  VFstate = rowVars(posterior_linpred(mod, 
                                      newdata= data %>% mutate(s_temp=0,c_order.temp=0,c_order.b = 0), 
                                      re_formula = NA,scale = "linear", resp="boldness2")),
  ##above: modified newdata because it is the variance of fixed effect assuming individuals only differ in state
  VI = (VarCorr(mod,summary=F)$id$sd[,"boldness2_Intercept"])^2,
  VIint = (VarCorr(mod,summary=F)$id$sd[,"boldness2_Intercept"])^2, ##identical to VI for boldness
  VB = (VarCorr(mod,summary=F)$box$sd[,"boldness2_Intercept"])^2,
  VBint = (VarCorr(mod,summary=F)$box$sd[,"boldness2_Intercept"])^2, ##identical to VB for boldness
  VD = (posterior_samples(mod,pars="sigma_boldness2")[,1])^2
  ) %>% 
  mutate(VP = select(.,c(VF,VI,VB,VD)) %>% rowSums() ) %>% 
  mutate(trait="Boldness",type="latent") %>% 
  mutate(.iteration = 1) %>% mutate(.iteration = cumsum(.iteration))

save(list=c("varcomps_bold_latent","varcomps_fpt_latent"), file=here("R_output","latent_varcomps.Rdata"))
}
```

Then we need to convert these latent variances to the observed/data scale. (Well, we don't strictly *need* to) We follow de Villemereuil et al 2016 (doi: 10.1534/genetics.115.186536) and 2018 (10.1111/jeb.13232) and use tools in their QGglmm package. 
Careful, this may take some time (about 2-3 hours on my laptop):

```{r obs-varcomps}
if(file.exists(here("R_output","obs_varcomps.Rdata")))
  {
  load(here("R_output","obs_varcomps.Rdata"))
  }else
    {
      
QGlognormal<-list(
  inv.link =function(x){exp(x)},
  var.func=function(x){0}, ##no supplementary distributional variance beyond the one in the log residuals (VD)
  d.inv.link=function(x){exp(x)} #derivative of exp is exp
)
##tested and checked; does give _exact_ observed scales and variances for a lognormal

array_fpt_latent <- varcomps_fpt_latent %>% select(beta0:VP) %>% array_tree(.,1) ##need to put as an array to work with map()

varcomps_fpt_obs=tibble(
                        VF=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VF"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VFstate=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VFstate"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VI=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VI"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VIint=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VIint"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VB=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VB"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VBint=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VBint"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VP=array_fpt_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VP"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector()
) %>% 
  mutate(VD = VP-(VF+VI+VB)) %>% ## VD is the residual, so VP minus the "named" components above
  select(VF:VBint,VD,VP) %>% ##just to keep in the same logical order as in the latent tab
  mutate(trait="Exploration",type= "obs") %>% 
  mutate(.iteration = 1) %>% mutate(.iteration = cumsum(.iteration))


###now we do the same for boldness

array_bold_latent <- varcomps_bold_latent %>% select(beta0:VP) %>% array_tree(.,1) 

varcomps_bold_obs=tibble(
                        VF=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VF"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VFstate=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VFstate"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VI=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VI"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VIint=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VIint"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VB=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VB"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VBint=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VBint"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector(),
                        VP=array_bold_latent %>%
                          map(.,~QGicc(mu=.["beta0"],var.comp=.["VP"],var.p=.["VP"],
                                       custom.model = QGlognormal,verbose=F)$var.comp.obs) %>% as_vector()
) %>% 
  mutate(VD = VP-(VF+VI+VB)) %>% ## VD is the residual, so VP minus the "named" components above
  select(VF:VBint,VD,VP) %>% ##just to keep in the same logical order as in the latent tab
  mutate(trait="Boldness",type= "obs") %>% 
  mutate(.iteration = 1) %>% mutate(.iteration = cumsum(.iteration))


vc_obs=rbind(varcomps_fpt_obs,varcomps_bold_obs)


save(list="vc_obs", file=here("R_output","obs_varcomps.Rdata"))
    }

vc_obs %>% pivot_longer(VF:VP) %>% group_by(trait,type,name) %>% mean_hdi(value)
```

If you poke around, you may notice that the VP you get here is higher than what you'd obtain simply by doing var(observations). This is normal, because censoring artificially limits the latter. The former is closer to what we'd actually have observed if we could have observed all snails until they expressed the behaviour of interest (in theory at least).

We extract information on repeatabilities on the way:

```{r repeatabilities}
###
vc_obs %>% 
  group_by(trait) %>%
  transmute(R_within_state= VIint/VP,
            Rtot = (VIint + VFstate)/ VP ,
            state_proportion = VFstate / (VIint + VFstate)
            ) %>% 
  mutate(.iteration = 1) %>% mutate(.iteration = cumsum(.iteration)) %>% 
  pivot_longer(-c(trait,.iteration)) %>% 
  group_by(name,.add = TRUE) %>% 
  mean_hdi(value)
```

Now we can make Figure 3:

```{r figure3}

#show relative variance components
vc_obs %>% 
  group_by(trait) %>% 
  pivot_longer(cols=c(VF:VBint,VD),names_to = "varcomp" , values_to = "variance") %>% 
  mutate(varcomp=fct_relevel(varcomp,c("VD","VIint","VI","VBint","VB","VFstate","VF"))) %>% 
  ggplot()+
  stat_halfeye(aes(y=varcomp,x=100*variance/VP),
                point_interval = mean_hdi,.width = 0.001,
                normalize="xy")+
  facet_wrap(~trait)+
  scale_x_continuous(name="Variance explained (%, observed scale)", lim=c(0,100),
                     breaks=seq(from=0,to=100,by=10))+
  scale_y_discrete(name="Variance component",
                   labels=c(expression(italic(V[D])),
                            expression(italic(V[I(intercept)])),
                            expression(italic(V[I])),
                            expression(italic(V[B(intercept)])),
                            expression(italic(V[B])),
                            expression(italic(V[F(state)])),
                            expression(italic(V[F]))
                            )) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95",colour.minor = "grey95")
```

## Cross-environmental correlation

It may also be interesting to see whether the individual variance $V_{I}$ in exploration varies across the temperature gradient, and if it does, whether it varies so strongly that it results in rank reversals. The low random slope variance indicates it is unlikely to do so, but to check this more rigorously, we can use the tool proposed in Brommer 2013 (doi: 10.1007/s00265-013-1603-9)(We're going to do that on the latent-scale only, however)

```{r}
phi <- matrix(c(1,1,range(data$s_temp)),nrow=2) 

# phi is a matrix including the two extreme positions on the environmental gradient we want to contrast

#then we need the individual latent covariance matrix, and to apply equations (4) to (6) in Brommer 2013

across_envts=VarCorr(mod,summary=FALSE)$id$cov %>%   
  array_tree(margin=1) %>% 
  tibble() %>% 
  rename(VCV=".") %>% 
  mutate(r_cross=map(.x=VCV,
                     .f=function(VCV=.x,PHI=phi){
                       P = PHI  %*% VCV[1:2,1:2] %*% t(PHI) ## equation (4)
                       return(P[1,2]/sqrt(P[1,1]*P[2,2]))   ## equation (5 and 6)
                     })) %>%
  mutate(Vi_ratio=map(.x=VCV,
                     .f=function(VCV=.x,PHI=phi){
                       P = PHI  %*% VCV[1:2,1:2] %*% t(PHI)
                       return(P[1,1]/P[2,2])     ##based on equation (5)
                     })) %>% 
  unnest(c(r_cross,Vi_ratio) )
  
  
  mean_hdi(across_envts$r_cross)
  mean_hdi(across_envts$Vi_ratio)
```

Our `r_cross` metric here is the cross-environmental correlation, while our `Vi_ratio` is the ratio $\frac{V_{I[lowestT]}}{V_{I[highestT]}}$ (on the latent scale).

### Figure 4

```{r figure4}

BLUPS_bold<-ranef(mod,summary=FALSE)$id[,,"boldness2_Intercept"] %>% 
  as_tibble() %>% 
  pivot_longer(everything()) %>% 
  group_by(name) %>% 
  mean_hdi() %>% 
  ungroup() %>% 
  arrange(name)

BLUPS_fpt<-ranef(mod,summary=FALSE)$id[,,"fpt_Intercept"] %>% 
  as_tibble() %>% 
  pivot_longer(everything()) %>% 
  group_by(name) %>% 
  mean_hdi() %>% 
  ungroup() %>% 
  arrange(name)


fig4_main <- tibble(
  bold=BLUPS_bold$value,
  fpt=BLUPS_fpt$value,
  boldCIlow=BLUPS_bold$.lower,
  boldCIhigh=BLUPS_bold$.upper,
  fptCIlow=BLUPS_fpt$.lower,
  fptCIhigh=BLUPS_fpt$.upper
  )%>% 
  ggplot()+
  geom_segment(aes(x=boldCIlow,xend=boldCIhigh,y=fpt,yend=fpt),col = "grey", show.legend = FALSE,alpha=0.5)+
  geom_segment(aes(x=bold,xend=bold,y=fptCIlow,yend=fptCIhigh),col = "grey", show.legend = FALSE,alpha=0.5)+
  geom_point(aes(x=bold,y=fpt))+
  scale_x_continuous(name = "Boldness (individual random effect)")+
  scale_y_continuous(name = "Exploration (individual random effect)")+
  theme_half_open(11)

fig4_inset <- tibble(
  cor = VarCorr(mod,summary=FALSE)$id$cor[,"boldness2_Intercept","fpt_Intercept"]
) %>% 
  ggplot()+
  geom_density(aes(x=cor),fill="white",col="black")+
  scale_x_continuous(name="",limits=c(-1,1),labels=c(-1,"",0,"",1))+
  scale_y_continuous(NULL,breaks=NULL)+
  geom_vline(xintercept = 0,lty=2)+
  theme(axis.line.y=element_blank(), panel.grid = element_blank())

fig4 <- ggdraw(fig4_main)+draw_plot(fig4_inset,x=0.73,y=0.115,height=0.25,width=0.25)

###arrow_bold
arrow_bold=ggplot()+
  geom_segment(aes(x=c(0.05,0.95),xend=c(0.95,0.05),y=c(0),yend=c(0)),arrow=arrow())+
  geom_text(aes(x=c(0,1),y=c(0,0),label=c("bolder","shyer")))+theme_void()

###arrow_speed
arrow_fpt=ggplot()+
  geom_segment(aes(x=c(0,0),xend=c(0,0),y=c(0.05,0.95),yend=c(0.95,0.05)),arrow=arrow())+
  geom_text(aes(x=c(0,0),y=c(0,1),label=c("faster","slower")))+theme_void()

arrow_fpt + fig4 + plot_spacer() + arrow_bold + plot_layout(nrow=2, widths=c(1,10),heights=c(10,1))

```

# Supplementary Materials

We also present a model in Supplementary Materials, on the differences in the % of 5-banded snails between the two source landscapes:

```{r supplementary-model}
data_shells<- data_shells0 %>% 
  mutate(Ntot=rowSums(select(.,N_0bands:N_5bands))) 

if(file.exists(here("R_output","model_suppl.Rdata")))
  {
  load(here("R_output","model_suppl.Rdata"))
  }else
    {

mod_S1 <- brm(N_5bands|trials(Ntot)~0+landscape,family=binomial,
      data=data_shells,
      prior=set_prior("normal(0,1.5)",class="b"),
      chains=4,iter=2000,warmup=1000,seed=42)

save(list="mod_S1", file=here("R_output","model_suppl.Rdata"))
}
```


```{r supplementary-model-summary}

summary(mod_S1)  # look at effective sample sizes

summary_mod_S1 <- mod_S1 %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_", "cor_", "sigma"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>% 
  print(n=Inf)

mcmc_rank_overlay(mod_S1, pars = summary_mod_S1$name)

data_shells %>% 
  add_fitted_draws(mod_S1) %>% 
  ungroup() %>% select(landscape,.value,Ntot) %>% 
  group_by(landscape) %>%
  mutate(.value=.value/Ntot) %>% 
  median_hdi()

##let's look at the difference
data_shells %>% 
  add_fitted_draws(mod_S1) %>% 
  ungroup() %>% select(landscape,.value,Ntot,.iteration,.draw) %>% 
  mutate(.value=.value/Ntot) %>% 
  compare_levels(variable=.value,by=landscape) %>% 
  median_hdi()


```


(Not shown in the manuscript or in supplementary Materials, and not fully evaluated _ cf priors, for instance). Note that it also works with a multinomial model if we want to account for all band numbers, and not just 5 vs. the rest
```{r supplementary-model-multi}
data_shells$y_shells <- with(data_shells, cbind(N_0bands,N_midband,N_2bands,N_3bands,N_5bands))

if(file.exists(here("R_output","model_suppl_alt.Rdata")))
  {
  load(here("R_output","model_suppl_alt.Rdata"))
  }else
    {

mod_S1bis <- brm(y_shells|trials(Ntot)~0+landscape,family=multinomial,
      data=data_shells,
      prior=set_prior("normal(0,1)",class="b",dpar =c("muN2bands","muN3bands","muN5bands","muNmidband")),
      chains=4,iter=2000,warmup=1000,seed=42)


save(list="mod_S1bis", file=here("R_output","model_suppl_alt.Rdata"))
}
```


```{r supplementary-model-multi-summary}


data_shells %>% 
  add_fitted_draws(mod_S1bis) %>% 
  ungroup() %>% select(landscape,.category,.value,Ntot) %>% 
  group_by(landscape,.category) %>%
  mutate(.value=.value/Ntot) %>% 
  median_hdi(.value)

data_shells %>% 
  add_fitted_draws(mod_S1bis) %>% 
  ungroup() %>% select(landscape,.category,.value,Ntot,.iteration,.draw) %>% 
  group_by(.category) %>% 
  mutate(.value=.value/Ntot) %>% 
  compare_levels(variable=.value,by=landscape) %>% 
  median_hdi()

```

